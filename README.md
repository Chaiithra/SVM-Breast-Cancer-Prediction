# ğŸ§  Breast Cancer Classification with SVM & PCA

## ğŸ“Œ Project Overview

This notebook focuses on building a classification model to distinguish between **Malignant** and **Benign** breast tumors using the **Breast Cancer Wisconsin Diagnostic dataset**. 

The pipeline includes full **EDA**, **feature importance**, **dimensionality reduction**, and **SVM-based classification** using both **Linear** and **RBF kernels**.

---

## ğŸ§± Notebook Structure

```text
1. ğŸ“¦ Importing Libraries
2. ğŸ“¥ Loading Dataset
3. ğŸ” Understanding Data
   â”œâ”€â”€ Removing 'id' column
   â”œâ”€â”€ Checking dtypes and NaN values
   â”œâ”€â”€ Checking for Duplicates
   â””â”€â”€ Statistical Summary
4. ğŸ“Š Exploratory Data Analysis (EDA)
   â”œâ”€â”€ Univariate Analysis
   â”œâ”€â”€ Box Plots
   â”œâ”€â”€ Distribution Plots (Histograms)
   â”‚   â”œâ”€â”€ Right-Skewed Features
   â”‚   â”œâ”€â”€ Left-Skewed Features
   â”‚   â””â”€â”€ Symmetrical Features
   â”œâ”€â”€ Why Skewness & Histograms Matter
   â””â”€â”€ What We Can Do
5. ğŸ”— Bivariate Analysis
   â””â”€â”€ Correlation Heatmap
6. ğŸŒŸ Feature Engineering
   â”œâ”€â”€ Feature Importance (Random Forest)
   â””â”€â”€ Label Encoding
7. ğŸ§  Model Training
   â”œâ”€â”€ Train-Test Split
   â”œâ”€â”€ SVM Pipeline + Grid Search CV
   â”œâ”€â”€ Best Models (Linear & RBF)
   â””â”€â”€ Refit and Evaluation
8. ğŸ“ˆ Evaluation
   â”œâ”€â”€ Classification Report
   â”œâ”€â”€ 2D Decision Boundary Visualization (PCA)
   â””â”€â”€ Learning Curves
## ğŸ’¡ Key Insights

- **Strong skewness** in several features was identified and addressed during the EDA phase.
- **Random Forest-based feature importance** revealed that features like `radius_mean`, `texture_mean`, and `perimeter_worst` are highly predictive.
- **PCA** enabled effective dimensionality reduction and helped us visualize decision boundaries in 2D space.
- The **RBF kernel SVM** slightly outperformed the **Linear kernel SVM** in terms of cross-validation accuracy, highlighting its strength in capturing nonlinear patterns.

---
```
## âœ… Key Takeaways

- Hands-on with all standard data transformation techniques.
- Clean, modular code with reusable functions.
- Statistical and ML-based outlier detection methods.
- Insightful visualizations at every step.

---

## ğŸ¤ Contribution

Want to contribute?
- â­ Star this repo to support the work
- ğŸ Found a bug or improvement? Open an issue
- ğŸš€ Fork and submit a pull request with enhancements

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See the [LICENSE](./LICENSE) file for details.

---

## ğŸš€ Future Work

- **Feature Importance Analysis** using more interpretable models like SHAP or LIME.
- **Dimensionality Reduction** with advanced techniques such as **UMAP**.
- Automate **Model Training Pipelines** using **Optuna** or **AutoML**.

---

## ğŸ“ How to Use

**1. Clone the Repo**
```bash
git clone https://github.com/Chaiithra/SVM-Breast-Cancer-Prediction.git
```

**2. Navigate to Project Directory**
```bash
cd breast-cancer-prediction
```

**3. Open the Notebook**
```bash
jupyter notebook SVM-Breast-Cancer-Prediction.ipynb
```

---

### ğŸ™Œ Acknowledgements
- **Dataset**: [Breast Cancer Dataset](https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset)  
- **Libraries Used**: Pandas, NumPy, Scikit-learn, Seaborn, Matplotlib, Label Encoders, etc.

---

### ğŸ“§ Contact  
Made with â¤ï¸ by **Chaiithra Thota**  

- ğŸ”— [Connect on LinkedIn](https://www.linkedin.com/in/chaiithrathota/)  
- ğŸ¦ [Connect on Twitter](https://x.com/DebugDiary_)  

